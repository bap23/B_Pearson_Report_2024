#!/bin/bash

# Script used to make PGS-MDD for UKB dataset
# Adapted from: PGS_ABCD_26_June_2023.sh
# Author: Bess Pearson 

#-------------------------------------------------------------------#
. /etc/profile.d/modules.sh                # Leave this line (enables the module command)
echo "Module command enabled."

module load rhel7/default-ccl              # REQUIRED - loads the basic environment
echo "Basic environment loaded."

source $(conda info --base)/etc/profile.d/conda.sh  

# -------------------------------------------------------------------#
# # Need to download the PRScs and the ldblk_1kg_eur from:
# # https://github.com/getian107/PRScs.git
# # make sure you are in correct working directory (e.g. cd /home/bp520/rds/hpc-work/PGS_UKB)
# -------------------------------------------------------------------#

# git clone https://github.com/getian107/PRScs.git

# wget "https://www.dropbox.com/s/t9opx2ty6ucrpib/ldblk_ukbb_eur.tar.gz?e=1&dl=0"  # downloads the ldblk_ukbb_eur
# tar -zxvf "ldblk_ukbb_eur.tar.gz?e=1&dl=0"    # will unzip the above file
# tar -zxvf "ldblk_ukbb_eur.tar.gz?e=1"

#-------------------------------------------------------------------#
# Still need to load the module for conda, and specific packages
#-------------------------------------------------------------------#

# conda init  # sets up the shell to recognize and use Conda's commands and environments
# conda info --envs   # used to display a list of conda environments, I initially just had the base environment
# conda create --name PRSenv # used to create a new conda environment, labelled "PRSenv"
# # conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge #increases the number of packages available to install via Conda
# # conda config --set remote_read_timeout_secs 1000

# conda install --name PRSenv scipy=1.11.0   # installs specific packages, scipy 
# # Downloaded older version (not 1.13.0 or 1.12.0, due to errors) --> https://scipy.github.io/devdocs/release/1.11.0-notes.html
# conda install --name PRSenv h5py    # installs specific packages, h5py 
# conda info --envs   # now showed that the PRSenv was created

conda activate PRSenv   # activates the Conda environment named PRSenv, assuming it's been previously created.
# conda list -n PRSenv    # should spit out a list of everything that is in the environment, can see the scipy and h5py are in the environment

echo "Conda PRSenv Activated, Running PRScs Now."

# -------------------------------------------------------------------#
# This will run the Python directory via: git clone https://github.com/getian107/PRScs.git
# -------------------------------------------------------------------#

# # Downloaded the .gz file from here: https://ipsych.dk/en/research/downloads/
# # Moved to hpc
# gunzip *.gz 
# head MDD # To determine which columns I needed (2, 4, 5, 9, 11)
# awk '{print $2, $4, $5, $9, $11}' MDD > PGS_UKB_MDD_Als_2023_noUKBor23Me.txt

python /home/bp520/rds/hpc-work/PGS_UKB/PRScs/PRScs.py --ref_dir=/home/bp520/rds/hpc-work/PGS_UKB/LD/ldblk_ukbb_eur --bim_prefix=/home/bp520/rds/rds-rb643-ukbiobank2/Data_Genetics/Genetic_data/Neuroimaging_samples/fileforclumping --sst_file=/home/bp520/rds/hpc-work/PGS_UKB/Zip_Files/MDD_zip/PGS_UKB_MDD_Als_2023_noUKBor23Me.txt --n_gwas=674452 --out_dir=/home/bp520/rds/hpc-work/PGS_UKB/MDD --phi=1e-2
# This line executes the Python script PRScs.py with specified parameters. 
# Parameters include references to directories (--ref_dir), input files (--bim_prefix, --sst_file), numerical values (--n_gwas, --phi), and an output directory (--out_dir).
echo "Job Finished"


# -------------------------------------------------------------------#
# Second Step:
# -------------------------------------------------------------------#
# Load modules: 
# Check which plink module is available in HPC: 
# module avail plink 
# /usr/local/software/spack/current/share/spack/tcl/linux-rhel7-x86_64 
# plink-1.07-gcc-5.4.0-34ob5b6  plink-1.9-gcc-5.4.0-sm3ojoi  
# /usr/local/Cluster-Config/modulefiles
# plink/2.00-alpha 

# Load the plink2 module:
module load plink/2.00-alpha

# Check plink2 version
plink2 --version

# Set paths
bim_prefix="/home/bp520/rds/rds-rb643-ukbiobank2/Data_Genetics/Genetic_data/Neuroimaging_samples/ukbchr_v2_r2correct_v2_"
all_chr_dir="/home/bp520/rds/hpc-work/PGS_UKB/MDD/all_chr_dir" # output I got from Step 1 of PGS
output_dir="/home/bp520/rds/hpc-work/PGS_UKB/MDD/individual_score"
# Create output directory if it doesn't exist
mkdir -p "${output_dir}"

for i in {1..22}; do plink2 --bfile "$bim_prefix${i}" --score "${all_chr_dir}/MDD_pst_eff_a1_b0.5_phi1e-02_chr${i}.txt" 2 4 6 center --out "${output_dir}/MDD_chr${i}"; done

# -------------------------------------------------------------------#
# Final step to generate PGS for UKB - MDD
# -------------------------------------------------------------------#
# # Generates individual PGS scores per individual (based on IID)
# # Author: Bess Pearson 

# # Set working directory: 
setwd("/home/bp520/rds/hpc-work/PGS_UKB/MDD/individual_score")

# # Load modules: 
# install.packages("data.table")
library(data.table)
# install.packages("dplyr")
library(dplyr)
# install.packages("tidyr")
library(tidyr)

# Define the directory containing the chromosome files
directory <- "/home/bp520/rds/hpc-work/PGS_UKB/MDD/individual_score"

# Get all chromosome files
file_paths <- list.files(directory, pattern = "MDD_chr.*\\.sscore", full.names = TRUE)

# Read and combine the data for each participant
combined_data <- rbindlist(lapply(file_paths, function(file) {
  data <- fread(file, select = c("IID", "SCORE1_AVG"))
  chromosome <- gsub("MDD_chr|\\.sscore", "", basename(file))
  data[, Chromosome := chromosome]
  return(data)
}))

# Aggregate SCORE1_AVG for each participant
aggregated_data <- combined_data[, .(SCORE1_AVG_SUM = sum(SCORE1_AVG)), by = .(IID)]

# Pivot the data to have one row per IID, with SCORE1_AVG values for each chromosome
combined_data_pivoted <- combined_data %>%
  pivot_wider(names_from = Chromosome, values_from = SCORE1_AVG, names_prefix = "chr", values_fn = list(SCORE1_AVG = sum), values_fill = NA)

# Join the pivoted data with the aggregated data
final_data <- combined_data_pivoted %>%
  left_join(aggregated_data, by = "IID")

# Rename the aggregated score column for clarity
final_data <- final_data %>%
  rename(finalsummedscore = SCORE1_AVG_SUM)

# Scale the summated PGS and assign it to a new column
final_data$scaledscore <- scale(final_data$finalsummedscore, center = TRUE, scale = TRUE)
# VARUNS SUGGESTION WITH SCALED DATA 

# Create a new folder for the final scores
final_score_directory <- "/home/bp520/rds/hpc-work/PGS_UKB/MDD/Final_Score"
dir.create(final_score_directory, showWarnings = FALSE)

# Write the final data to a file
output_file <- file.path(final_score_directory, "Final_PGS_MDD.txt")
write.table(final_data, file = output_file, sep = "\t", quote = FALSE, row.names = FALSE)
